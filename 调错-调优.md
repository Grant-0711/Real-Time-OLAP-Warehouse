# Flink消费Kafka消费不到

```java
org.apache.kafka.common.errors.TimeoutException:Timeout expired while fetching topic metadata
```

## 原因

kafka地址，zookeeper地址，broker地址等可能配置错误

总之是无法去指定的地址消费数据

# Flink任务提交报错

```shell
org.apache.flink.client.deployment.ClusterRetrieveException: Couldn't retrieve Yarn cluster

bin/flink run -d -t yarn-per-job -c\ com.grant.flink.java.chapter_2.Flink03_WC_UnBoundedStream \
./flink-prepare-1.0-SNAPSHOT.jar
```

## 原因

在flink run 参数指定中，-t后要指定运行模式

yarn-session

yarn-per-job

# idea compile error

```java
java.lang.NoClassDefFoundError: org/apache/flink/runtime/state/StateBackend
```

解决

edit configuration 中勾选  including dependencies with scope 'provide'



将配置表制作为流时，流的数据类型封装为java样例类，但是无法直接识别变量

```
Exception in thread "main" org.apache.flink.table.api.TableException: source_table is not found in PojoType<org.hxl.realtime.bean.TableProcess
```

解决

在查询配置表数据时为每一个字段起别名，一一对应